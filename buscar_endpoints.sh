#!/bin/bash
#
# Script para encontrar TODOS los endpoints de un dominio
# Usa mÃºltiples herramientas: katana, waybackurls, gau, gospider, etc.
#

TARGET="$1"

if [ -z "$TARGET" ]; then
    echo "Uso: $0 <dominio>"
    echo "Ejemplo: $0 trabajito.com.bo"
    exit 1
fi

OUTPUT_DIR="endpoints_${TARGET//./_}"

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘     Buscador de Endpoints - $TARGET"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Crear directorio
mkdir -p "$OUTPUT_DIR"
cd "$OUTPUT_DIR"

echo "ðŸŽ¯ Target: $TARGET"
echo "ðŸ“ Directorio: $OUTPUT_DIR"
echo ""

# ============================================================
# HERRAMIENTA 1: Katana
# ============================================================
echo "[1] Katana - Crawler moderno"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

if command -v katana &> /dev/null; then
    katana -u "https://$TARGET" \
        -d 5 \
        -jc \
        -f qurl \
        -ef woff,css,png,svg,jpg,woff2,jpeg,gif,svg,ico \
        -silent \
        -o katana_urls.txt 2>/dev/null

    count=$(wc -l < katana_urls.txt 2>/dev/null || echo 0)
    echo "  âœ“ URLs encontradas: $count"
else
    echo "  âš  Katana no instalado"
fi
echo ""

# ============================================================
# HERRAMIENTA 2: waybackurls
# ============================================================
echo "[2] waybackurls - Archive.org"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

if command -v waybackurls &> /dev/null; then
    waybackurls "$TARGET" 2>/dev/null | sort -u > wayback_urls.txt
    count=$(wc -l < wayback_urls.txt 2>/dev/null || echo 0)
    echo "  âœ“ URLs histÃ³ricas: $count"
else
    echo "  âš  waybackurls no instalado"
fi
echo ""

# ============================================================
# HERRAMIENTA 3: gau (GetAllURLs)
# ============================================================
echo "[3] gau - URLs de mÃºltiples fuentes"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

if command -v gau &> /dev/null; then
    gau "$TARGET" 2>/dev/null | sort -u > gau_urls.txt
    count=$(wc -l < gau_urls.txt 2>/dev/null || echo 0)
    echo "  âœ“ URLs encontradas: $count"
else
    echo "  âš  gau no instalado"
fi
echo ""

# ============================================================
# HERRAMIENTA 4: gospider
# ============================================================
echo "[4] gospider - Spider de Go"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

if command -v gospider &> /dev/null; then
    gospider -s "https://$TARGET" -d 3 -c 10 -t 20 -q 2>/dev/null | \
        grep -oE "https?://[^\s]+" | sort -u > gospider_urls.txt
    count=$(wc -l < gospider_urls.txt 2>/dev/null || echo 0)
    echo "  âœ“ URLs encontradas: $count"
else
    echo "  âš  gospider no instalado"
fi
echo ""

# ============================================================
# HERRAMIENTA 5: hakrawler
# ============================================================
echo "[5] hakrawler - Crawler rÃ¡pido"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

if command -v hakrawler &> /dev/null; then
    echo "https://$TARGET" | hakrawler -depth 3 -plain 2>/dev/null | \
        sort -u > hakrawler_urls.txt
    count=$(wc -l < hakrawler_urls.txt 2>/dev/null || echo 0)
    echo "  âœ“ URLs encontradas: $count"
else
    echo "  âš  hakrawler no instalado"
fi
echo ""

# ============================================================
# Combinar todas las URLs
# ============================================================
echo "[6] Combinando resultados..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

cat *.txt 2>/dev/null | sort -u > all_urls.txt
total=$(wc -l < all_urls.txt)
echo "  âœ“ Total URLs Ãºnicas: $total"
echo ""

# ============================================================
# Filtrar por categorÃ­as
# ============================================================
echo "[7] Clasificando endpoints..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Endpoints de API
grep -iE "(api|rest|graphql|v[0-9])" all_urls.txt | sort -u > api_endpoints.txt
echo "  âœ“ Endpoints API: $(wc -l < api_endpoints.txt)"

# URLs con parÃ¡metros
grep "?" all_urls.txt | sort -u > urls_with_params.txt
echo "  âœ“ URLs con parÃ¡metros: $(wc -l < urls_with_params.txt)"

# Archivos JavaScript
grep "\.js" all_urls.txt | grep -v "\.json" | sort -u > javascript_files.txt
echo "  âœ“ Archivos JavaScript: $(wc -l < javascript_files.txt)"

# Archivos JSON
grep "\.json" all_urls.txt | sort -u > json_files.txt
echo "  âœ“ Archivos JSON: $(wc -l < json_files.txt)"

# Archivos interesantes
grep -iE "\.(xml|txt|pdf|doc|docx|xls|xlsx|csv|sql|db|bak|zip|tar|gz|env|config)$" all_urls.txt | \
    sort -u > interesting_files.txt
echo "  âœ“ Archivos interesantes: $(wc -l < interesting_files.txt)"

# Endpoints de admin/panel
grep -iE "(admin|panel|dashboard|login|auth)" all_urls.txt | sort -u > admin_endpoints.txt
echo "  âœ“ Endpoints de admin: $(wc -l < admin_endpoints.txt)"

echo ""

# ============================================================
# Resultados finales
# ============================================================
echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                    RESULTADOS FINALES                           â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

echo "ðŸ“Š EstadÃ­sticas:"
echo "  Total URLs: $total"
echo "  Endpoints API: $(wc -l < api_endpoints.txt)"
echo "  URLs con parÃ¡metros: $(wc -l < urls_with_params.txt)"
echo "  Archivos JavaScript: $(wc -l < javascript_files.txt)"
echo "  Archivos JSON: $(wc -l < json_files.txt)"
echo "  Archivos interesantes: $(wc -l < interesting_files.txt)"
echo "  Endpoints admin: $(wc -l < admin_endpoints.txt)"
echo ""

# Mostrar primeros resultados
echo "ðŸ” Top 15 endpoints de API:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
head -15 api_endpoints.txt

echo ""
echo "ðŸ” Archivos JavaScript:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
head -10 javascript_files.txt

echo ""
echo "ðŸ” Endpoints de admin:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
cat admin_endpoints.txt

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "âœ… BÃºsqueda completada"
echo "ðŸ“ Resultados en: $(pwd)"
echo ""

# Listar archivos generados
echo "ðŸ“„ Archivos generados:"
ls -lh *.txt

echo ""
